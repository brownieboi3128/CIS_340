{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-623ecb49dce2cff2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Ex: 6.4: Classification Using Scikit-learn\n",
    "\n",
    "- Objective: We will revisit the World Happiness Report (WHR) data for this exercise, bringing in some additional information that will enable us to formulate a classification problem to predict categorical labels on the dataset. Our goal is to build a classifier that we will train on a subset of the WHR numerical data (x) and the region data (y), so that we can predict regions from data for countries that we have not trained our model on.\n",
    "\n",
    "- **Requires data files: `WHR2018Chapter2OnlineData.xls`**\n",
    "\n",
    "- **Demonstrates**:\n",
    "    - Working with the `StandardScaler` object to standardize the data.\n",
    "    - `svm` and `tree`  classifiers from scikit-learn to classify the data.\n",
    "    - Using the `train_test_split` function to split the data into training and testing sets.\n",
    "    - `accuracy_score` to evaluate the performance of the classifier.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code cell below to import some modules and read in and preprocess the WHR data as we have done previously.  The last line in the code cell below returns the head of the basic WHR dataframe, to remind you what is in that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-528dcd796b7a9020",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.723590</td>\n",
       "      <td>0.517637</td>\n",
       "      <td>0.258195</td>\n",
       "      <td>7.168690</td>\n",
       "      <td>0.450662</td>\n",
       "      <td>49.209663</td>\n",
       "      <td>0.718114</td>\n",
       "      <td>0.181819</td>\n",
       "      <td>0.881686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2009</td>\n",
       "      <td>4.401778</td>\n",
       "      <td>0.583926</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>7.333790</td>\n",
       "      <td>0.552308</td>\n",
       "      <td>49.624432</td>\n",
       "      <td>0.678896</td>\n",
       "      <td>0.203614</td>\n",
       "      <td>0.850035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2010</td>\n",
       "      <td>4.758381</td>\n",
       "      <td>0.618265</td>\n",
       "      <td>0.275324</td>\n",
       "      <td>7.386629</td>\n",
       "      <td>0.539075</td>\n",
       "      <td>50.008961</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.137630</td>\n",
       "      <td>0.706766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>3.831719</td>\n",
       "      <td>0.611387</td>\n",
       "      <td>0.267175</td>\n",
       "      <td>7.415019</td>\n",
       "      <td>0.521104</td>\n",
       "      <td>50.367298</td>\n",
       "      <td>0.495901</td>\n",
       "      <td>0.175329</td>\n",
       "      <td>0.731109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2012</td>\n",
       "      <td>3.782938</td>\n",
       "      <td>0.710385</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>7.517126</td>\n",
       "      <td>0.520637</td>\n",
       "      <td>50.709263</td>\n",
       "      <td>0.530935</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.775620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  year  Happiness  Positive  Negative    LogGDP   Support  \\\n",
       "0  Afghanistan  2008   3.723590  0.517637  0.258195  7.168690  0.450662   \n",
       "1  Afghanistan  2009   4.401778  0.583926  0.237092  7.333790  0.552308   \n",
       "2  Afghanistan  2010   4.758381  0.618265  0.275324  7.386629  0.539075   \n",
       "3  Afghanistan  2011   3.831719  0.611387  0.267175  7.415019  0.521104   \n",
       "4  Afghanistan  2012   3.782938  0.710385  0.267919  7.517126  0.520637   \n",
       "\n",
       "        Life   Freedom  Generosity  Corruption  \n",
       "0  49.209663  0.718114    0.181819    0.881686  \n",
       "1  49.624432  0.678896    0.203614    0.850035  \n",
       "2  50.008961  0.600127    0.137630    0.706766  \n",
       "3  50.367298  0.495901    0.175329    0.731109  \n",
       "4  50.709263  0.530935    0.247159    0.775620  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dfraw = pd.read_excel('WHR2018Chapter2OnlineData.xls', sheet_name='Table2.1')\n",
    "cols_to_include = ['country', 'year', 'Life Ladder', \n",
    "                   'Positive affect','Negative affect',\n",
    "                   'Log GDP per capita', 'Social support',\n",
    "                   'Healthy life expectancy at birth', \n",
    "                   'Freedom to make life choices', \n",
    "                   'Generosity', 'Perceptions of corruption']\n",
    "renaming = {'Life Ladder': 'Happiness', \n",
    "            'Log GDP per capita': 'LogGDP', \n",
    "            'Social support': 'Support', \n",
    "            'Healthy life expectancy at birth': 'Life', \n",
    "            'Freedom to make life choices': 'Freedom', \n",
    "            'Perceptions of corruption': 'Corruption', \n",
    "            'Positive affect': 'Positive', \n",
    "            'Negative affect': 'Negative'}\n",
    "df = dfraw[cols_to_include].rename(renaming, axis=1)\n",
    "key_vars = ['Happiness', 'LogGDP', 'Support', 'Life', 'Freedom', 'Generosity', 'Corruption', 'Positive', 'Negative']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-114766d8d149ad20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 1.\n",
    "\n",
    "We will first augment the core WHR dataset that we have been working with to bring in some additional information that is included in a different worksheet in the WHR spreadsheet.  Since this is mostly about data processing rather than machine learning, simply execute the next two code cells below.  But study each line of code and the associated comments, and then examine the head of the new dataframe named ```df2``` to understand what has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4961999f914bb49e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country                        region\n",
       "0  Afghanistan                    South Asia\n",
       "1      Albania    Central and Eastern Europe\n",
       "2      Algeria  Middle East and North Africa\n",
       "3       Angola            Sub-Saharan Africa\n",
       "4    Argentina   Latin America and Caribbean"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data from SupportingFactors worksheet into a new dataframe dfsupp\n",
    "dfsupp = pd.read_excel('WHR2018Chapter2OnlineData.xls', sheet_name='SupportingFactors')\n",
    "\n",
    "# extract out region information from SupportingFactors dataframe\n",
    "regions = dfsupp[['country', 'Region indicator']].rename({'Region indicator': 'region'}, axis=1)\n",
    "\n",
    "# examine head of regions dataframe -- each country has an associated world region\n",
    "regions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04c2e566637e8957",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>3.806614</td>\n",
       "      <td>0.580873</td>\n",
       "      <td>0.301283</td>\n",
       "      <td>7.419697</td>\n",
       "      <td>0.517146</td>\n",
       "      <td>50.838271</td>\n",
       "      <td>0.544895</td>\n",
       "      <td>0.118428</td>\n",
       "      <td>0.826794</td>\n",
       "      <td>South Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>4.988791</td>\n",
       "      <td>0.642628</td>\n",
       "      <td>0.303256</td>\n",
       "      <td>9.247059</td>\n",
       "      <td>0.723204</td>\n",
       "      <td>68.027213</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>-0.105019</td>\n",
       "      <td>0.859691</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>5.555004</td>\n",
       "      <td>0.616524</td>\n",
       "      <td>0.265460</td>\n",
       "      <td>9.501728</td>\n",
       "      <td>0.804633</td>\n",
       "      <td>64.984461</td>\n",
       "      <td>0.536398</td>\n",
       "      <td>-0.208236</td>\n",
       "      <td>0.661478</td>\n",
       "      <td>Middle East and North Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>4.420299</td>\n",
       "      <td>0.613339</td>\n",
       "      <td>0.351173</td>\n",
       "      <td>8.713935</td>\n",
       "      <td>0.737973</td>\n",
       "      <td>51.729801</td>\n",
       "      <td>0.455957</td>\n",
       "      <td>-0.077940</td>\n",
       "      <td>0.867018</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>6.406131</td>\n",
       "      <td>0.840998</td>\n",
       "      <td>0.273187</td>\n",
       "      <td>9.826051</td>\n",
       "      <td>0.906080</td>\n",
       "      <td>66.764205</td>\n",
       "      <td>0.753122</td>\n",
       "      <td>-0.154544</td>\n",
       "      <td>0.844038</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Happiness  Positive  Negative    LogGDP   Support       Life  \\\n",
       "country                                                                     \n",
       "Afghanistan   3.806614  0.580873  0.301283  7.419697  0.517146  50.838271   \n",
       "Albania       4.988791  0.642628  0.303256  9.247059  0.723204  68.027213   \n",
       "Algeria       5.555004  0.616524  0.265460  9.501728  0.804633  64.984461   \n",
       "Angola        4.420299  0.613339  0.351173  8.713935  0.737973  51.729801   \n",
       "Argentina     6.406131  0.840998  0.273187  9.826051  0.906080  66.764205   \n",
       "\n",
       "              Freedom  Generosity  Corruption                        region  \n",
       "country                                                                      \n",
       "Afghanistan  0.544895    0.118428    0.826794                    South Asia  \n",
       "Albania      0.626155   -0.105019    0.859691    Central and Eastern Europe  \n",
       "Algeria      0.536398   -0.208236    0.661478  Middle East and North Africa  \n",
       "Angola       0.455957   -0.077940    0.867018            Sub-Saharan Africa  \n",
       "Argentina    0.753122   -0.154544    0.844038   Latin America and Caribbean  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the mean values of all the WHR data for each country, averaging over all years in the dataset\n",
    "dfmean = df.groupby('country').mean().drop('year', axis=1)\n",
    "\n",
    "# merge the mean WHR data with the region information extracted previously\n",
    "df2 = pd.merge(dfmean, regions, on='country').dropna()\n",
    "\n",
    "# set the index of df2 to be the country name\n",
    "df2.set_index('country', inplace=True)\n",
    "\n",
    "# examine head of df2 dataframe -- mean WHR values for each country, along with associated regions\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3ebf9c19dc4374f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 2.\n",
    "\n",
    "It is this new dataframe ```df2``` that we want to use for machine learning.  For each country in the dataset, we have a set of mean numerical values ('Happiness', 'Positive', 'Negative', etc., which are all listed in the variable ```key_vars``` defined above) and a categorical value ('region').  \n",
    "\n",
    "#### We would like to know if the raw numerical data are  predictive of the region.  In other words, if someone gave you a set of numerical data on Happiness, etc. for an unknown country, would you be able to predict what region of the world it might be located in?  This is an example of classification, where we will train a model based on the numerical data and the associated labels (regions).\n",
    "\n",
    "In order to proceed, we first want to extract and process some data from our ```df2``` dataframe.  We need to separate the data into two parts:\n",
    "* the ```region data``` that we want to be able to predict (we'll call it ```y```)\n",
    "* the ```WHR numerical data``` that we want to use as input to our prediction (we'll call it ```x```)\n",
    "\n",
    "In the code cell below:\n",
    "* Extract the subset of ```df2``` associated with the columns in ```key_vars``` and assign it to the variable ```x```.\n",
    "* Extract the subset of ```df2``` associated with the region column, and assign it to the variable ```y```.\n",
    "* Print the shape of both `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01ec5c8a944da95a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (152, 9)\n",
      "Shape of y: (152,)\n"
     ]
    }
   ],
   "source": [
    "# Extract the subset of df2 associated with the columns in key_vars and assign it to the variable x.\n",
    "x = df2[key_vars]\n",
    "\n",
    "# Extract the subset of df2 associated with the region column, and assign it to the variable y.\n",
    "y = df2['region']\n",
    "\n",
    "# Print the shape of both x and y.\n",
    "print(\"Shape of x:\", x.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c7c2b22581801780",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 3.\n",
    "\n",
    "You should note that the shape of ```x``` is (152, 9) and the shape of ```y``` is (152,).  This is similar to what we saw in the earlier exercise on hand-written digits!  There are 152 samples (countries), and 9 features (each of the key_vars) that we are making predictions from.\n",
    "\n",
    "Because the numerical data columns in ```x``` represent different quantities and have different scales, we have to preprocess the data some more to remove that source of variation. We will use one here called ```StandardScaler```, which will transform a data set so that each resulting column has zero mean and unit standard deviation. More about Standardization the the StandardScaler class can be found [here](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler).\n",
    "\n",
    "First examine, and then execute the code cell below.  This code does the following:\n",
    "* imports the `StandardScaler` object\n",
    "* creates and fits a `StandardScaler` object to our dataframe ```x```\n",
    "* creates a new dataframe ```x_scaled``` that contains the scaled (transformed) data, using the column and index labels from the unscaled dataframe ```x```\n",
    "* prints out the mean and standard deviation of each column of ```x_scaled```\n",
    "* peeks at the head of the new dataframe ```x_scaled```\n",
    "\n",
    "In examining the output, check that the means of each column have been scaled to nearly zero (to within a very small tolerance) and the standard deviations have been scaled to one. Some of the very small numbers might be printed out in scientific notation, where a number like ```1.928282e-16``` means ```1.928282 * 10**(-16)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-54c74ff720e1fb98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiness     1.782200e-16\n",
      "LogGDP        6.135443e-17\n",
      "Support      -2.337312e-16\n",
      "Life         -5.843279e-17\n",
      "Freedom       6.748987e-16\n",
      "Generosity    1.168656e-17\n",
      "Corruption    9.349247e-17\n",
      "Positive      1.811417e-16\n",
      "Negative      2.337312e-16\n",
      "dtype: float64\n",
      "Happiness     1.0\n",
      "LogGDP        1.0\n",
      "Support       1.0\n",
      "Life          1.0\n",
      "Freedom       1.0\n",
      "Generosity    1.0\n",
      "Corruption    1.0\n",
      "Positive      1.0\n",
      "Negative      1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Happiness</th>\n",
       "      <th>LogGDP</th>\n",
       "      <th>Support</th>\n",
       "      <th>Life</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Corruption</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>-1.443128</td>\n",
       "      <td>-1.438896</td>\n",
       "      <td>-2.425953</td>\n",
       "      <td>-1.333584</td>\n",
       "      <td>-1.397623</td>\n",
       "      <td>0.735439</td>\n",
       "      <td>0.451854</td>\n",
       "      <td>-1.262731</td>\n",
       "      <td>0.471370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albania</th>\n",
       "      <td>-0.360792</td>\n",
       "      <td>0.054466</td>\n",
       "      <td>-0.681799</td>\n",
       "      <td>0.776161</td>\n",
       "      <td>-0.776670</td>\n",
       "      <td>-0.719736</td>\n",
       "      <td>0.632648</td>\n",
       "      <td>-0.638194</td>\n",
       "      <td>0.499009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>0.157600</td>\n",
       "      <td>0.262588</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.402698</td>\n",
       "      <td>-1.462554</td>\n",
       "      <td>-1.391919</td>\n",
       "      <td>-0.456675</td>\n",
       "      <td>-0.902184</td>\n",
       "      <td>-0.030449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>-0.881273</td>\n",
       "      <td>-0.381215</td>\n",
       "      <td>-0.556782</td>\n",
       "      <td>-1.224159</td>\n",
       "      <td>-2.077245</td>\n",
       "      <td>-0.543385</td>\n",
       "      <td>0.672914</td>\n",
       "      <td>-0.934399</td>\n",
       "      <td>1.170248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>0.936845</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.866136</td>\n",
       "      <td>0.621142</td>\n",
       "      <td>0.193546</td>\n",
       "      <td>-1.042257</td>\n",
       "      <td>0.546624</td>\n",
       "      <td>1.367958</td>\n",
       "      <td>0.077797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Happiness    LogGDP   Support      Life   Freedom  Generosity  \\\n",
       "country                                                                      \n",
       "Afghanistan  -1.443128 -1.438896 -2.425953 -1.333584 -1.397623    0.735439   \n",
       "Albania      -0.360792  0.054466 -0.681799  0.776161 -0.776670   -0.719736   \n",
       "Algeria       0.157600  0.262588  0.007447  0.402698 -1.462554   -1.391919   \n",
       "Angola       -0.881273 -0.381215 -0.556782 -1.224159 -2.077245   -0.543385   \n",
       "Argentina     0.936845  0.527632  0.866136  0.621142  0.193546   -1.042257   \n",
       "\n",
       "             Corruption  Positive  Negative  \n",
       "country                                      \n",
       "Afghanistan    0.451854 -1.262731  0.471370  \n",
       "Albania        0.632648 -0.638194  0.499009  \n",
       "Algeria       -0.456675 -0.902184 -0.030449  \n",
       "Angola         0.672914 -0.934399  1.170248  \n",
       "Argentina      0.546624  1.367958  0.077797  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(x)\n",
    "x_scaled = pd.DataFrame(scaler.fit_transform(x), columns = x.columns, index = x.index)\n",
    "\n",
    "print(np.mean(x_scaled, axis=0))\n",
    "print(np.std(x_scaled, axis=0))\n",
    "\n",
    "x_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-120c4b66e20c858b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 4.\n",
    "\n",
    "Now that the data have been preprocessed, we can begin with our classification analysis. Execute the code cell below to import:\n",
    "* the ```svm``` and ```tree``` submodules\n",
    "* the ```train_test_split``` function\n",
    "* the ```accuracy_score``` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7b61fbfb465b7fba",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e4b3a68ad0f3755",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 5.\n",
    "\n",
    "One of the functions that we imported above is called ```train_test_split```.  As its name suggests, this function splits a dataset into separate training and testing sets.  The [online documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train_test_split#sklearn-model-selection-train-test-split) indicates that it splits a dataset randomly, such that approximately 25% of the data winds up in the test set and the remaining 75% in the training set.  Here, we want to split up 2 arrays (```x_scaled``` and ```y```) into coordinated test and train sets, so that the function will return a total of 4 subarrays (```x_train, x_test, y_train, y_test```).\n",
    "\n",
    "In the code cell below, enter and execute a call to ```train_test_split``` that takes ```x_scaled``` and ```y``` as inputs, along with the optional parameter ```random_state=0```, and returns the 4 data subsets mentioned above, to be named as ```x_train```, ```x_test```, ```y_train```, ```y_test```.  The online documentation provides an example of what such a function call looks like. After the function call, print the shapes of each of the four arrays that are returned.\n",
    "- ```random_state``` set to 0 will ensure that the same random split is generated each time the function is called. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (114, 9)\n",
      "Shape of x_test: (38, 9)\n",
      "Shape of y_train: (114,)\n",
      "Shape of y_test: (38,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, random_state=0)\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-effebc5e9940ed25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 6.\n",
    "\n",
    "Having split our datasets, we want to first train a classifier on our training data so that we can apply it to the testing data.  One way of assessing the performance of a classifier is by computing its accuracy score on the test data, that is, what fraction of the test data are correctly predicted by the classifier.  Fortunately, `sklearn` provides a built-in function named ```accuracy_score``` that carries out this computation. You can read more about it in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy_score#sklearn.metrics.accuracy_score).\n",
    "\n",
    "\n",
    "We will first build the SVM Classifier. In the code cell below:\n",
    "* create a new ```svm.SVC()``` object and assign it to the variable ```clf1``` \n",
    "* call the ```fit``` method on ```clf1``` with the `x` and `y` training data (i.e., training the model to associate ```x_train``` with ```y_train```)\n",
    "* call the ```predict``` method on ```clf1``` on the `x` testing data and assign the result to the variable ```predictions1```, in order to make predictions for those inputs\n",
    "* call the ```accuracy_score``` function on the `y` testing data and the test predictions you generated and assign the result to the variable ```score1```\n",
    "* print the value of ```score1```\n",
    "\n",
    "The accuracy score is a fraction between 0 and 1 indicating the fraction of predictions that match the true value in the test set. The accuracy score reported should be around 71% (0.71)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fa487bf06d148c8d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7105263157894737\n"
     ]
    }
   ],
   "source": [
    "clf1 = svm.SVC()\n",
    "clf1.fit(x_train, y_train)\n",
    "predictions1 = clf1.predict(x_test)\n",
    "score1 = accuracy_score(y_test, predictions1)\n",
    "print(\"SVM Accuracy:\", score1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d8cd9531f6db2bc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 7.\n",
    "\n",
    "Build a second classifier based on Decision Trees as supported by the ```tree``` module.\n",
    "\n",
    "In the code cell below:\n",
    "\n",
    "* Create a new ```tree.DecisionTreeClassifier()``` object with the optional argument ```random_state=0```, and assign it to the variable ```clf2``` (`clf2` stands for \"classifier number 2\", so that we can compare with ```clf1``` above).\n",
    "* Call the ```fit``` method on ```clf2``` with the `x` and `y` training data (i.e., training the model to associate ```x_train``` with ```y_train```).\n",
    "* Call the ```predict``` method on ```clf2``` on the `x` testing data and assign the result to the variable ```predictions2```, in order to make predictions for those inputs.\n",
    "* Call the ```accuracy_score``` function on the `y` testing data and the test predictions you generated and assign the result to the variable ```score2```.\n",
    "* Print the value of ```score2```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-da49b9de6d360166",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7631578947368421\n"
     ]
    }
   ],
   "source": [
    "clf2 = tree.DecisionTreeClassifier(random_state=0)\n",
    "clf2.fit(x_train, y_train)\n",
    "predictions2 = clf2.predict(x_test)\n",
    "score2 = accuracy_score(y_test, predictions2)\n",
    "print(\"Decision Tree Accuracy:\", score2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0d4bfe43911002ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 8.\n",
    "#### Compare the classifiers.\n",
    "\n",
    "Given that ```train_test_split``` can produce different random splits, let's compare the two classifiers &mdash; ```clf1``` (SVM) and ```clf2``` (Decision Tree) &mdash; for different splits.\n",
    "\n",
    "In the code cell below, write some code to do the following:\n",
    "* write a Python `for` loop so that you can run through the loop 20 times\n",
    "* within each pass through the loop, do the following:\n",
    "    * call `test_train_split` on ```x_scaled``` and ```y``` to get new random instances of `x_train`, `x_test`, `y_train`, `y_test` -- in this case, you don't want to pass in a value for ```random_state``` since you want to get different random splits each time\n",
    "    * fit each of the classifiers `clf1` and `clf2` to `x_train` and `y_train`\n",
    "    * run predictions on each of the classifiers `clf1` and `clf2` on the `x` testing data\n",
    "    * compute the accuracy_score of each of the two classifiers on the test data and the test predictions you generated \n",
    "    * print the score of each classifier, as well as their difference (hint: ```print(score1, score2, score1-score2)``` to get just one line of output per iteration of the loop)\n",
    "    \n",
    "Execute the code you have written.  You should see it run through the loop 20 times, for different random data splits. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4b11d4e6c2398273",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6052631578947368 0.631578947368421 -0.02631578947368418\n",
      "0.631578947368421 0.6052631578947368 0.02631578947368418\n",
      "0.6052631578947368 0.6052631578947368 0.0\n",
      "0.6052631578947368 0.631578947368421 -0.02631578947368418\n",
      "0.5 0.4473684210526316 0.05263157894736842\n",
      "0.6052631578947368 0.6842105263157895 -0.07894736842105265\n",
      "0.7631578947368421 0.5789473684210527 0.1842105263157895\n",
      "0.631578947368421 0.631578947368421 0.0\n",
      "0.631578947368421 0.4473684210526316 0.18421052631578944\n",
      "0.6578947368421053 0.5789473684210527 0.07894736842105265\n",
      "0.5789473684210527 0.6842105263157895 -0.10526315789473684\n",
      "0.6052631578947368 0.5526315789473685 0.05263157894736836\n",
      "0.7631578947368421 0.6052631578947368 0.1578947368421053\n",
      "0.6842105263157895 0.5526315789473685 0.13157894736842102\n",
      "0.47368421052631576 0.5263157894736842 -0.05263157894736842\n",
      "0.7105263157894737 0.631578947368421 0.07894736842105265\n",
      "0.7368421052631579 0.631578947368421 0.10526315789473684\n",
      "0.5789473684210527 0.47368421052631576 0.10526315789473689\n",
      "0.7631578947368421 0.7105263157894737 0.052631578947368474\n",
      "0.5789473684210527 0.5526315789473685 0.02631578947368418\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_scaled, y)\n",
    "    clf1.fit(x_train, y_train)\n",
    "    predictions1 = clf1.predict(x_test)\n",
    "    score1 = accuracy_score(y_test, predictions1)\n",
    "\n",
    "    clf2.fit(x_train, y_train)\n",
    "    predictions2 = clf2.predict(x_test)\n",
    "    score2 = accuracy_score(y_test, predictions2)\n",
    "\n",
    "    print(score1, score2, score1 - score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-01de5a27c9f1842e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 9.\n",
    "\n",
    "Generate a visual summary of the relative performance of the two classifiers, for a larger number of runs.\n",
    "\n",
    "In the code cell below, copy and paste the code you wrote above and modify it to do the following:\n",
    "\n",
    "* prior to entering the `for` loop, initialize two empty lists named ```all_scores1``` and ```all_scores2``` that will be used to collect the scores of each classifier each time through the loop\n",
    "* run through the loop 1000 times instead of 20 as before\n",
    "* append the scores (```score1``` and ```score2```) to each of the lists used to contain all the scores\n",
    "* remove the print statement so that you don't get 1000 annoying print statements when you run the code\n",
    "* once the loop is finished, use the ```plt.hist``` function to plot histograms for ```all_scores1``` and ```all_scores2``` together in the same plot\n",
    "    * you can accomplish this by making two successive calls to the histogram function within the same code cell\n",
    "    * you might want to add options to change the number of bins for the histograms\n",
    "    * you should change the alpha value (opacity) of the histogram plots so that you can see both distributions, since at full opacity, the second one plotted will obscure the first one\n",
    "    * you should use the ``label`` option to label the datasets\n",
    "* After making your two calls to ```plt.hist```, you should call ``plt.legend`` to produce a legend on the plot that will identify the two datasets based on the label options that you added to your ```plt.hist``` calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-28a13e824292104e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28c1b8eac60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_scores1 = []\n",
    "all_scores2 = []\n",
    "\n",
    "for i in range(1000):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_scaled, y)\n",
    "    clf1.fit(x_train, y_train)\n",
    "    predictions1 = clf1.predict(x_test)\n",
    "    score1 = accuracy_score(y_test, predictions1)\n",
    "    all_scores1.append(score1)\n",
    "\n",
    "    clf2.fit(x_train, y_train)\n",
    "    predictions2 = clf2.predict(x_test)\n",
    "    score2 = accuracy_score(y_test, predictions2)\n",
    "    all_scores2.append(score2)  \n",
    "    \n",
    "plt.hist(all_scores1, bins=20, alpha=0.5, label='clf1')\n",
    "plt.hist(all_scores2, bins=20, alpha=0.5, label='clf2')\n",
    "plt.legend(loc='upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
