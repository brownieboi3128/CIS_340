{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ex: 3.11: Reading Tables from a Relational Database\n",
    "\n",
    "- **Objective**: Read tables from a relational database and use fundamental SQL operations including SELECT, FROM, WHERE, and ORDER BY to query and manipulate data.\n",
    "\n",
    "- **Requires data files: `product_data.sqlite`**\n",
    "\n",
    "- **Demonstrates**:\n",
    "    - Reading tables from a relational database.\n",
    "    - SELECT, FROM, WHERE, and ORDER BY SQL operations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8ce176ae1d985e55",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The SQLAlchemy package in Python enables one to connect to a SQL database and extract data based on SQL queries into Pandas DataFrames. To begin, we need to install the SQLAlchemy package. Execute the following code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\brown\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Downloading SQLAlchemy-2.0.38-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.1 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "Successfully installed greenlet-3.1.1 sqlalchemy-2.0.38\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue with a couple imports &mdash; execute the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dd1a3c109930ac61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48b4d1c24ef57b34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 1.\n",
    "\n",
    "You will be working with a sqlite database named `\"product_data.sqlite\"`. sqlite is a relational database management system that support SQL databases in files, as opposed to residing on a separate database server somewhere.\n",
    "\n",
    "Execute the code cell below. It contains an expression that creates a sqlalchemy engine object by connecting to the \"product_data.sqlite\" database, and assigns that object to variable `engine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca81cca1d514cc94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///product_data.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6642adada4505056",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 2.\n",
    "\n",
    "Since a relational database can hold multiple tables, it's useful to be able to determine what tables are contained in a database. The inspect module in SQLAlchemy provides a method called `get_table_names` that returns a list of table names in the database.\n",
    "\n",
    "- Pass the engine object to the `inspect` function to create an inspector object. Then, use the `get_table_names` method to assign the list of table names to the variable `tables`, and print the value of `tables`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-212c29bb79e33f31",
     "locked": true,
     "schema_version": 1,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inventory', 'orders', 'sales']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "tables = inspector.get_table_names()\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e95e285cbaf31f18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 3.\n",
    "\n",
    "Following the examples shown in the course notebook, in the code cell below, write and evaluate three statements to extract the sales, orders, and inventory tables from the databases, and assign each of those dataframes to an associated variable (named ```sales```, ```orders```, and ```inventory```, respectively).  Inspect each of the three dataframes, either by printing them out in the cell below, or adding additional code cells to inspect the contents of each dataframe individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-820e78f7a0c6cbc6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Pens  Pencils  Erasers  Paper\n",
      "0    Jan   800      950      320    920\n",
      "1    Feb   430      530      265    470\n",
      "2    Mar   175      228      240    190\n",
      "3    Apr   525      503      320    590\n",
      "4    May   325      228      279    365\n",
      "5    Jun   200       58      254    181\n",
      "6    Jul  1150     1378      644   1281\n",
      "7    Aug   725      778      554    776\n",
      "8    Sep   302      198      459    251\n",
      "9    Oct   602      473      499    451\n",
      "10   Nov   497      367      487    248\n",
      "11   Dec   419      298      472    149\n",
      "  Month  Pens  Pencils  Erasers  Paper\n",
      "0   Jan  1200     1500      400   1400\n",
      "1   Apr   500      500      100    600\n",
      "2   Jul  1000     1400      400   1200\n",
      "3   Oct   500      500      100    600\n",
      "   Month  Pens  Pencils  Erasers  Paper\n",
      "0    Jan   400      550       80    480\n",
      "1    Feb   370      420       55    450\n",
      "2    Mar   255      302       25    280\n",
      "3    Apr   150      225       20    200\n",
      "4    May   200      275       41    225\n",
      "5    Jun   125      170       25    184\n",
      "6    Jul    50       80       10    100\n",
      "7    Aug   425      600       90    505\n",
      "8    Sep   423      580       95    525\n",
      "9    Oct   200      225       60    400\n",
      "10   Nov   105      106       12    203\n",
      "11   Dec    78       69       15     99\n"
     ]
    }
   ],
   "source": [
    "inventory = pd.read_sql_query(\"SELECT * FROM inventory\", engine)\n",
    "print(inventory)\n",
    "orders = pd.read_sql_query(\"SELECT * FROM orders\", engine)\n",
    "print(orders)\n",
    "sales = pd.read_sql_query(\"SELECT * FROM sales\", engine)\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d007f0f52a1ece18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 4.\n",
    "\n",
    "Inspect the `inventory table`. You will see a column named `paper`. Imagine you want to know when your inventory of paper is too large, say, more than 700 reams.  In the code cell below, write and evaluate an expression to extract the rows in which the paper inventory is more than 700. Assign the database output to the variable ```too_much_paper```, and examine the extracted dataframe.\n",
    "\n",
    "Hint: \n",
    "If you are uncertain about how to write this query, take a moment to reflect on the example provided on our course notebook site. In the course notebook, the following SQL query is used to illustrate one way you can refine a query to return very precise information from a database.\n",
    "\n",
    "`low_inventory = pd.read_sql_query('SELECT * from inventory where (Pencils < 200) or (Pens < 200) or (Erasers < 50) or (Paper < 300)', engine)`\n",
    "\n",
    "This query asks the `inventory` table to return all of its records where either the value in the `Pencils` column is less than 200 or the value in the `Pens` column is less than 200 or the value in the `Erasers` column is less than 50 or the value in the `Paper` column is less than 300.\n",
    "\n",
    "Because you are asked to return rows where `Paper` is greater than 700, you won't need all of the additional `or` statements that check the values in other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc51ca51f1e556d8",
     "locked": true,
     "schema_version": 1,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Month  Pens  Pencils  Erasers  Paper\n",
      "0   Feb   430      530      265    470\n",
      "1   Mar   175      228      240    190\n",
      "2   Apr   525      503      320    590\n",
      "3   May   325      228      279    365\n",
      "4   Jun   200       58      254    181\n",
      "5   Sep   302      198      459    251\n",
      "6   Oct   602      473      499    451\n",
      "7   Nov   497      367      487    248\n",
      "8   Dec   419      298      472    149\n"
     ]
    }
   ],
   "source": [
    "too_much_paper = pd.read_sql_query(\"SELECT * FROM inventory where (Paper < 700)\", engine)\n",
    "print(too_much_paper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-111df7832baaf2fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Step 5.\n",
    "\n",
    "SQL queries provide a wide range of functionalities.  For example, you can numerically sort the rows in the output with the keywords ```order by```.  Imagine you have a SQL query like 'select [MAIN QUERY]' where MAIN_QUERY reflects whatever you're extracting from the database; you can tack on to the end of a SQL query string additional query details of the form:\n",
    "\n",
    "* 'select [MAIN QUERY] order by COLUMN_NAME' : to sort the output based on the specified COLUMN_NAME in ascending order (default)\n",
    "\n",
    "* 'select [MAIN QUERY] order by COLUMN_NAME desc' : to sort the output based on the specified COLUMN_NAME in descending order\n",
    "\n",
    "In the code cell below, write and evaluate an expression to extract all the sales data (using the 'select * from sales' query you've used previously), sorted in descending order by the Paper sales in each month.  Assign the result to the variable ```top_paper_sales``` and inspect the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5440e5d05f4d5d9b",
     "locked": true,
     "schema_version": 1,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month  Pens  Pencils  Erasers  Paper\n",
      "0    Jul  1150     1378      644   1281\n",
      "1    Jan   800      950      320    920\n",
      "2    Aug   725      778      554    776\n",
      "3    Apr   525      503      320    590\n",
      "4    Feb   430      530      265    470\n",
      "5    Oct   602      473      499    451\n",
      "6    May   325      228      279    365\n",
      "7    Sep   302      198      459    251\n",
      "8    Nov   497      367      487    248\n",
      "9    Mar   175      228      240    190\n",
      "10   Jun   200       58      254    181\n",
      "11   Dec   419      298      472    149\n"
     ]
    }
   ],
   "source": [
    "top_paper_sales = pd.read_sql_query(\"SELECT * FROM inventory order by Paper desc\", engine)\n",
    "print(top_paper_sales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
